{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Modules\n",
    "import uproot\n",
    "import awkward\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.figure as figure\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from Sum import Sum\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from numpy.lib.recfunctions import structured_to_unstructured\n",
    "from tensorflow.keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set hyperparameters\n",
    "MASKVAL = -999\n",
    "MAXTRACKS = 8\n",
    "BATCHSIZE = 64\n",
    "EPOCHS = 1000\n",
    "MAXEVENTS = 99999999999999999\n",
    "# VALFACTOR = 10\n",
    "LR = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Callbacks\n",
    "\n",
    "# Define Early Stopping\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001,\n",
    "    patience = 50,\n",
    "    restore_best_weights = True,\n",
    ")\n",
    "\n",
    "#Define ReducedLR\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the root file\n",
    "tree = uproot.open(\"hffrag.root:CharmAnalysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which branches of the tree we actually want to look at\n",
    "# Not currently used!\n",
    "branches = \\\n",
    "  [ \\\n",
    "\n",
    "  # true jet information\n",
    "   \"AnalysisAntiKt4TruthJets_pt\"\n",
    "   , \"AnalysisAntiKt4TruthJets_eta\"\n",
    "   , \"AnalysisAntiKt4TruthJets_phi\"\n",
    "   , \"AnalysisAntiKt4TruthJets_m\"\n",
    "\n",
    "\n",
    "  # true b-hadron information\n",
    "  # these b-hadrons are inside the truth jets\n",
    "   , \"AnalysisAntiKt4TruthJets_ghostB_pdgId\"\n",
    "    , \"AnalysisAntiKt4TruthJets_ghostB_pt\"\n",
    "   , \"AnalysisAntiKt4TruthJets_ghostB_eta\"\n",
    "   , \"AnalysisAntiKt4TruthJets_ghostB_phi\"\n",
    "   , \"AnalysisAntiKt4TruthJets_ghostB_m\"\n",
    "  \n",
    "\n",
    "  # reconstructed jet information\n",
    "   , \"AnalysisJets_pt_NOSYS\"\n",
    "   , \"AnalysisJets_eta\"\n",
    "   , \"AnalysisJets_phi\"\n",
    "   , \"AnalysisJets_m\"\n",
    "\n",
    "\n",
    "  # reconstructed track information\n",
    "  , \"AnalysisTracks_pt\"\n",
    "  , \"AnalysisTracks_eta\"\n",
    "  , \"AnalysisTracks_phi\"\n",
    "  , \"AnalysisTracks_z0sinTheta\"\n",
    "  , \"AnalysisTracks_d0sig\"\n",
    "  , \"AnalysisTracks_d0\"\n",
    "  , \"AnalysisTracks_d0sigPV\"\n",
    "  , \"AnalysisTracks_d0PV\"\n",
    "  ]\n",
    "\n",
    "\n",
    "  # True jet information\n",
    "jetfeatures = \\\n",
    "  [ \"AnalysisAntiKt4TruthJets_pt\"\n",
    "  , \"AnalysisAntiKt4TruthJets_eta\"\n",
    "  , \"AnalysisAntiKt4TruthJets_phi\"\n",
    "  , \"AnalysisAntiKt4TruthJets_ghostB_pt\"\n",
    "  ]\n",
    "\n",
    "# true b-hadron information\n",
    "# these b-hadrons are inside the truth jets\n",
    "bhadfeatures = \\\n",
    "   [ \"AnalysisAntiKt4TruthJets_ghostB_pt\"\n",
    "   , \"AnalysisAntiKt4TruthJets_ghostB_eta\"\n",
    "   , \"AnalysisAntiKt4TruthJets_ghostB_phi\"\n",
    "   , \"AnalysisAntiKt4TruthJets_ghostB_m\"\n",
    "   ]\n",
    "  \n",
    "\n",
    "# reconstructed track information\n",
    "trackfeatures = \\\n",
    "  [ \"AnalysisTracks_pt\"\n",
    "  , \"AnalysisTracks_eta\"\n",
    "  , \"AnalysisTracks_phi\"\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the requested branches from the file\n",
    "features = tree.arrays(jetfeatures + trackfeatures + branches, entry_stop=MAXEVENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141465\n",
      "141465\n"
     ]
    }
   ],
   "source": [
    "jetz0sintheta = features[\"AnalysisTracks_z0sinTheta\"]\n",
    "impactParam = features[\"AnalysisTracks_d0\"]\n",
    "impactParamSig = features[\"AnalysisTracks_d0sig\"]\n",
    "impactParamPV = features[\"AnalysisTracks_d0PV\"]\n",
    "impactParamPVSig = features[\"AnalysisTracks_d0sigPV\"]\n",
    "print(len(jetz0sintheta))\n",
    "print(len(impactParam))\n",
    "fig = \\\n",
    "  binneddensity \\\n",
    "  ( jetz0sintheta[:,0] # the first jet in each event\n",
    "  , fixedbinning(0, 2, 100) # 50 bins from 0 to 2\n",
    "  , xlabel=\"Transverse IP * sin(Theta)\"\n",
    "  )\n",
    "fig.savefig(\"TransverseIP.png\")\n",
    "\n",
    "fig = \\\n",
    "  binneddensity \\\n",
    "  ( impactParam[:,0] # the first jet in each event\n",
    "  , fixedbinning(-1, 1, 100) # 50 bins from 0 to 2\n",
    "  , xlabel=\"Impact Parameter\"\n",
    "  )\n",
    "fig.savefig(\"Impact Parameter.png\")\n",
    "\n",
    "fig = \\\n",
    "  binneddensity \\\n",
    "  ( impactParamSig[:,0] # the first jet in each event\n",
    "  , fixedbinning(-3, 3, 100) # 50 bins from 0 to 2\n",
    "  , xlabel=\"Impact Parameter Sig\"\n",
    "  )\n",
    "fig.savefig(\"Impact Parameter Sig.png\")\n",
    "\n",
    "fig = \\\n",
    "  binneddensity \\\n",
    "  ( impactParamPV[:,0] # the first jet in each event\n",
    "  , fixedbinning(-1, 1, 100) # 50 bins from 0 to 2\n",
    "  , xlabel=\"Impact Parameter (PV)\"\n",
    "  )\n",
    "fig.savefig(\"Impact Parameter PV.png\")\n",
    "\n",
    "fig = \\\n",
    "  binneddensity \\\n",
    "  ( impactParamPVSig[:,0] # the first jet in each event\n",
    "  , fixedbinning(-3, 3, 100) # 50 bins from 0 to 2\n",
    "  , xlabel=\"Impact Parameter Sig (PV)\"\n",
    "  )\n",
    "fig.savefig(\"Impact Parameter PV Sig.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find where angular distance is small\n",
    "def matchTracks(jets, trks):\n",
    "  jeteta = jets[\"AnalysisAntiKt4TruthJets_eta\"] \n",
    "  jetphi = jets[\"AnalysisAntiKt4TruthJets_phi\"]\n",
    "\n",
    "  trketas = trks[\"AnalysisTracks_eta\"]\n",
    "  trkphis = trks[\"AnalysisTracks_phi\"]\n",
    "\n",
    "  detas = jeteta - trketas\n",
    "  dphis = numpy.abs(jetphi - trkphis)\n",
    "\n",
    "  # deal with delta phis being annoying\n",
    "  awkward.where(dphis > numpy.pi, dphis - numpy.pi, dphis)\n",
    "\n",
    "  return numpy.sqrt(dphis**2 + detas**2) < 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting from polar to cartesian\n",
    "\n",
    "#Used for jets\n",
    "def ptetaphi2pxpypz(ptetaphi):\n",
    "  pts = ptetaphi[:,0:1]\n",
    "  etas = ptetaphi[:,1:2]\n",
    "  phis = ptetaphi[:,2:3]\n",
    "\n",
    "  pxs = pts * numpy.cos(phis)\n",
    "  pys = pts * numpy.sin(phis)\n",
    "  pzs = pts * numpy.sinh(etas)\n",
    "\n",
    "  isinf = numpy.isinf(pzs)\n",
    "\n",
    "  if numpy.any(isinf):\n",
    "    print(\"inf from eta:\")\n",
    "    print(etas[isinf])\n",
    "    raise ValueError(\"infinity from sinh(eta)\")\n",
    "\n",
    "  return numpy.concatenate([pxs, pys, pzs], axis=1)\n",
    "\n",
    "#Used for tracks\n",
    "def ptetaphi2pxpypz2(ptetaphi):\n",
    "  pts = ptetaphi[:,:,0:1]\n",
    "  etas = ptetaphi[:,:,1:2]\n",
    "  phis = ptetaphi[:,:,2:3]\n",
    "\n",
    "  mask = pts == MASKVAL\n",
    "  #Looking in array and testing a condition - if finds mask, replaces mask with pt value\n",
    "  pxs = numpy.where(mask, pts, pts * numpy.cos(phis)) # Apply transformation only to actual pT\n",
    "  pys = numpy.where(mask, pts, pts * numpy.sin(phis))\n",
    "  pzs = numpy.where(mask, pts, pts * numpy.sinh(etas))\n",
    "\n",
    "  isinf = numpy.isinf(pzs)\n",
    "\n",
    "  if numpy.any(isinf):\n",
    "    print(\"inf from eta:\")\n",
    "    print(etas[isinf])\n",
    "    raise ValueError(\"infinity from sinh(eta)\")\n",
    "\n",
    "  return numpy.concatenate([pxs, pys, pzs], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pads inputs with nans up to the given maxsize\n",
    "def pad(xs, maxsize):\n",
    "  #Find 'none' values in array and replace with MASKVAL (= fill_none)\n",
    "  ys = \\\n",
    "    awkward.fill_none \\\n",
    "  ( awkward.pad_none(xs, maxsize, axis=1, clip=True) #Adding 'none' values to make sure it is correct size\n",
    "  , MASKVAL\n",
    "  )[:,:maxsize]\n",
    "\n",
    "  return awkward.to_regular(ys, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten1(xs, maxsize=-1):\n",
    "  ys = {}\n",
    "  for field in xs.fields:\n",
    "    zs = xs[field]\n",
    "    if maxsize > 0:\n",
    "      zs = pad(zs, maxsize)\n",
    "    ys[field] = zs\n",
    "\n",
    "  return awkward.zip(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define histogram plotting functions\n",
    "# returns a fixed set of bin edges\n",
    "def fixedbinning(xmin, xmax, nbins):\n",
    "  return numpy.mgrid[xmin:xmax:nbins*1j]\n",
    "\n",
    "\n",
    "# define two functions to aid in plotting\n",
    "def hist(xs, binning, normalized=False):\n",
    "  ys = numpy.histogram(xs, bins=binning)[0]\n",
    "\n",
    "  yerrs = numpy.sqrt(ys)\n",
    "\n",
    "  if normalized:\n",
    "    s = numpy.sum(ys)\n",
    "    ys = ys / s\n",
    "    yerrs = yerrs / s\n",
    "\n",
    "  return ys, yerrs\n",
    "\n",
    "\n",
    "def binneddensity(xs, binning, label=None, xlabel=None, ylabel=\"binned probability density\"):\n",
    "  fig = figure.Figure(figsize=(8, 8))\n",
    "  plt = fig.add_subplot(111)\n",
    "\n",
    "  ys , yerrs = hist(xs, binning, normalized=True)\n",
    "\n",
    "  # determine the central value of each histogram bin\n",
    "  # as well as the width of each bin\n",
    "  # this assumes a fixed bin size.\n",
    "  xs = (binning[1:]+binning[:-1]) / 2.0\n",
    "  xerrs = ((binning[1:]-binning[:-1]) / 2.0)\n",
    "\n",
    "  plt.errorbar \\\n",
    "    ( xs\n",
    "    , ys\n",
    "    , xerr=xerrs\n",
    "    , yerr=yerrs\n",
    "    , label=label\n",
    "    , linewidth=0\n",
    "    , elinewidth=2\n",
    "    )\n",
    "\n",
    "  plt.set_xlabel(xlabel)\n",
    "  plt.set_ylabel(ylabel)\n",
    "\n",
    "  return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = \\\n",
    "  features[awkward.sum(features[\"AnalysisAntiKt4TruthJets_pt\"] > 25000, axis=1) > 0]\n",
    "\n",
    "jets = events[jetfeatures][:,0] #First jet\n",
    "tracks = events[trackfeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchedtracks = tracks[matchTracks(jets, tracks)] \n",
    "matchedtracks = flatten1(matchedtracks, MAXTRACKS) #Turn into regular np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "bjets = awkward.sum(jets[\"AnalysisAntiKt4TruthJets_ghostB_pt\"] > 5000, axis=1) > 0 #Find b hadron jets with momentum\n",
    "jets = jets[bjets] #Jets identified as b jets are only jets considered\n",
    "bhads = jets[\"AnalysisAntiKt4TruthJets_ghostB_pt\"][:,0] #np Stack here - Each sub array contains all the features of the jet (axis -1)\n",
    "matchedtracks = matchedtracks[bjets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "jets = structured_to_unstructured(jets[jetfeatures[:-1]]) #number of features\n",
    "matchedtracks = structured_to_unstructured(matchedtracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jets = ptetaphi2pxpypz(jets).to_numpy()\n",
    "tracks = ptetaphi2pxpypz2(matchedtracks.to_numpy())\n",
    "bhads = bhads.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the training model\n",
    "\n",
    "tracklayers = [ 32 , 32 , 32 , 32 , 32 ]\n",
    "jetlayers = [ 64 , 64 , 64 , 64 , 64 ]\n",
    "\n",
    "def buildModel(tlayers, jlayers, ntargets):\n",
    "  inputs = layers.Input(shape=(None, tlayers[0]))\n",
    "\n",
    "  outputs = inputs\n",
    "  outputs = layers.Masking(mask_value=MASKVAL)(outputs)\n",
    "\n",
    "  for nodes in tlayers[:-1]:\n",
    "    outputs = layers.TimeDistributed(layers.Dense(nodes, activation='relu'))(outputs)\n",
    "    outputs = layers.BatchNormalization()(outputs)\n",
    "\n",
    "  outputs = layers.TimeDistributed(layers.Dense(tlayers[-1], activation='softmax'))(outputs)\n",
    "  outputs = Sum()(outputs)\n",
    "\n",
    "  for nodes in jlayers:\n",
    "    outputs = layers.Dense(nodes, activation='relu')(outputs)\n",
    "    outputs = layers.BatchNormalization()(outputs)\n",
    "\n",
    "  outputs = layers.Dense(ntargets + ntargets*(ntargets+1)//2)(outputs)\n",
    "\n",
    "  return \\\n",
    "    keras.Model \\\n",
    "    ( inputs = inputs\n",
    "    , outputs = outputs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generalise loss to n targets\n",
    "##Convert b hadron features to cartesian\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the loss function\n",
    "# this ignores any dimension beyond the first!\n",
    "def LogNormal1D(true, meanscovs):\n",
    "  ntargets = true.shape[1] #Number of variables predicting\n",
    "  means = meanscovs[:,:ntargets] #First n targets are the means\n",
    "  # ensure diagonal is positive\n",
    "  logsigma = meanscovs[:,ntargets:2*ntargets]\n",
    "  rest = meanscovs[:,2*ntargets:]\n",
    "\n",
    "  # TODO\n",
    "  # build matrix\n",
    "\n",
    "  return ((means[:,0] - true[:,0])**2 / (2*keras.backend.exp(logsigma[:,0])**2)) + logsigma[:,0] #Change to sum over each variable (for loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = buildModel([len(trackfeatures)] + tracklayers, jetlayers, 1)\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "model.compile \\\n",
    "  ( loss = LogNormal1D\n",
    "  , optimizer = keras.optimizers.Adam(learning_rate=LR)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits the data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(tracks, bhads, train_size = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains the data\n",
    "history = model.fit(X_train, y_train, validation_data = (X_valid, y_valid), batch_size=BATCHSIZE, callbacks =[early_stopping, reduce_lr], epochs=EPOCHS)\n",
    "\n",
    "history_df = numpy.log(pd.DataFrame(history.history))\n",
    "fig=plt.figure()\n",
    "LossFigure = history_df.loc[:, ['loss', 'val_loss']].plot().get_figure()\n",
    "LossFigure.savefig('Loss.png')\n",
    "\n",
    "\n",
    "# Plot and save exponential function [TODO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the model to predict validation set\n",
    "pred = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the variables we want from the model\n",
    "pTDiff=pred[:,0] - y_valid\n",
    "Err= numpy.exp(pred[:,1])\n",
    "Pull = pTDiff/Err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the plots\n",
    "#The loss curve\n",
    "\n",
    "\n",
    "# The Histograms\n",
    "fig = \\\n",
    "binneddensity \\\n",
    "( Pull\n",
    ", fixedbinning(-10, 10, 1000)\n",
    ", xlabel=\"Pull\"\n",
    ")\n",
    "fig.savefig(\"Pull.png\")\n",
    "\n",
    "fig = \\\n",
    "binneddensity \\\n",
    "( pTDiff\n",
    ", fixedbinning(-400000, 400000, 1000)\n",
    ", xlabel=\"pT Difference\"\n",
    ")\n",
    "fig.savefig(\"pT Difference.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print any results we want\n",
    "print('pT Diff Mean = ' + str(numpy.mean(pTDiff)))\n",
    "print('pT Diff Median = ' + str(numpy.median(pTDiff)))\n",
    "print('pT Diff Std = ' + str(numpy.std(pTDiff)))\n",
    "print('pT Diff IQR = ' + str(numpy.percentile(pTDiff, 75)-numpy.percentile(pTDiff, 25)))\n",
    "print('Pull Mean = ' + str(numpy.mean(Pull)))\n",
    "print('Pull Median = ' + str(numpy.median(Pull)))\n",
    "print('Pull Std = ' + str(numpy.std(Pull)))\n",
    "print('Pull IQR = ' + str(numpy.percentile(Pull, 75)-numpy.percentile(Pull, 25)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Luke')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6679b2c4fdeb25d2a0cd890f27b2b235b752c32ed605315ad831eb2b3957fc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
