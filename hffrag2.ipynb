{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Modules\n",
    "import uproot\n",
    "import awkward\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.figure as figure\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from Sum import Sum\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from numpy.lib.recfunctions import structured_to_unstructured\n",
    "from tensorflow.keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set hyperparameters\n",
    "MASKVAL = -999\n",
    "MAXTRACKS = 8\n",
    "BATCHSIZE = 64\n",
    "EPOCHS = 1000\n",
    "MAXEVENTS = 99999999999999999\n",
    "# VALFACTOR = 10\n",
    "LR = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Callbacks\n",
    "\n",
    "# Define Early Stopping\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001,\n",
    "    patience = 20,\n",
    "    restore_best_weights = True,\n",
    ")\n",
    "\n",
    "#Define ReducedLR\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.8,\n",
    "                              patience=10, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the root file\n",
    "tree = uproot.open(\"hffrag.root:CharmAnalysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which branches of the tree we actually want to look at\n",
    "# Not currently used!\n",
    "branches = \\\n",
    "  [ \\\n",
    "\n",
    "  # true jet information\n",
    "   \"AnalysisAntiKt4TruthJets_pt\"\n",
    "   , \"AnalysisAntiKt4TruthJets_eta\"\n",
    "   , \"AnalysisAntiKt4TruthJets_phi\"\n",
    "   , \"AnalysisAntiKt4TruthJets_m\"\n",
    "\n",
    "\n",
    "  # true b-hadron information\n",
    "  # these b-hadrons are inside the truth jets\n",
    "   , \"AnalysisAntiKt4TruthJets_ghostB_pdgId\"\n",
    "    , \"AnalysisAntiKt4TruthJets_ghostB_pt\"\n",
    "   , \"AnalysisAntiKt4TruthJets_ghostB_eta\"\n",
    "   , \"AnalysisAntiKt4TruthJets_ghostB_phi\"\n",
    "   , \"AnalysisAntiKt4TruthJets_ghostB_m\"\n",
    "  \n",
    "\n",
    "  # reconstructed jet information\n",
    "   , \"AnalysisJets_pt_NOSYS\"\n",
    "   , \"AnalysisJets_eta\"\n",
    "   , \"AnalysisJets_phi\"\n",
    "   , \"AnalysisJets_m\"\n",
    "\n",
    "\n",
    "  # reconstructed track information\n",
    "  , \"AnalysisTracks_pt\"\n",
    "  , \"AnalysisTracks_eta\"\n",
    "  , \"AnalysisTracks_phi\"\n",
    "  , \"AnalysisTracks_z0sinTheta\"\n",
    "  , \"AnalysisTracks_d0sig\"\n",
    "  , \"AnalysisTracks_d0\"\n",
    "  , \"AnalysisTracks_d0sigPV\"\n",
    "  , \"AnalysisTracks_d0PV\"\n",
    "  ]\n",
    "\n",
    "\n",
    "  # True jet information\n",
    "jetfeatures = \\\n",
    "  [ \"AnalysisAntiKt4TruthJets_pt\"\n",
    "  , \"AnalysisAntiKt4TruthJets_eta\"\n",
    "  , \"AnalysisAntiKt4TruthJets_phi\"\n",
    "  , \"AnalysisAntiKt4TruthJets_ghostB_pt\"\n",
    "  , \"AnalysisAntiKt4TruthJets_ghostB_eta\"\n",
    "  , \"AnalysisAntiKt4TruthJets_ghostB_phi\"\n",
    "  ]\n",
    "\n",
    "# true b-hadron information\n",
    "# these b-hadrons are inside the truth jets\n",
    "bhadfeatures = \\\n",
    "   [ \"AnalysisAntiKt4TruthJets_ghostB_pt\"\n",
    "   , \"AnalysisAntiKt4TruthJets_ghostB_eta\"\n",
    "   , \"AnalysisAntiKt4TruthJets_ghostB_phi\"\n",
    "   , \"AnalysisAntiKt4TruthJets_ghostB_m\"\n",
    "   ]\n",
    "  \n",
    "\n",
    "# reconstructed track information\n",
    "trackfeatures = \\\n",
    "  [ \"AnalysisTracks_pt\"\n",
    "  , \"AnalysisTracks_eta\"\n",
    "  , \"AnalysisTracks_phi\"\n",
    "  #, \"AnalysisTracks_z0sinTheta\"\n",
    "  #, \"AnalysisTracks_d0sig\"\n",
    "  #, \"AnalysisTracks_d0\"\n",
    "  #, \"AnalysisTracks_d0sigPV\"\n",
    "  #, \"AnalysisTracks_d0PV\"\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the requested branches from the file\n",
    "features = tree.arrays(jetfeatures + trackfeatures + branches, entry_stop=MAXEVENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find where angular distance is small\n",
    "def matchTracks(jets, trks):\n",
    "  jeteta = jets[\"AnalysisAntiKt4TruthJets_eta\"] \n",
    "  jetphi = jets[\"AnalysisAntiKt4TruthJets_phi\"]\n",
    "\n",
    "  trketas = trks[\"AnalysisTracks_eta\"]\n",
    "  trkphis = trks[\"AnalysisTracks_phi\"]\n",
    "\n",
    "  detas = jeteta - trketas\n",
    "  dphis = numpy.abs(jetphi - trkphis)\n",
    "\n",
    "  # deal with delta phis being annoying\n",
    "  awkward.where(dphis > numpy.pi, dphis - numpy.pi, dphis)\n",
    "\n",
    "  return numpy.sqrt(dphis**2 + detas**2) < 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting from polar to cartesian\n",
    "\n",
    "#Used for jets\n",
    "def ptetaphi2pxpypz(ptetaphi):\n",
    "  pts = ptetaphi[:,0:1]\n",
    "  etas = ptetaphi[:,1:2]\n",
    "  phis = ptetaphi[:,2:3]\n",
    "\n",
    "  pxs = pts * numpy.cos(phis)\n",
    "  pys = pts * numpy.sin(phis)\n",
    "  pzs = pts * numpy.sinh(etas)\n",
    "\n",
    "  isinf = numpy.isinf(pzs)\n",
    "\n",
    "  if numpy.any(isinf):\n",
    "    print(\"inf from eta:\")\n",
    "    print(etas[isinf])\n",
    "    raise ValueError(\"infinity from sinh(eta)\")\n",
    "\n",
    "  return numpy.concatenate([pxs, pys, pzs], axis=1)\n",
    "\n",
    "#Used for tracks\n",
    "def ptetaphi2pxpypz2(ptetaphi):\n",
    "  pts = ptetaphi[:,:,0:1]\n",
    "  etas = ptetaphi[:,:,1:2]\n",
    "  phis = ptetaphi[:,:,2:3]\n",
    "\n",
    "  mask = pts == MASKVAL\n",
    "  #Looking in array and testing a condition - if finds mask, replaces mask with pt value\n",
    "  pxs = numpy.where(mask, pts, pts * numpy.cos(phis)) # Apply transformation only to actual pT\n",
    "  pys = numpy.where(mask, pts, pts * numpy.sin(phis))\n",
    "  pzs = numpy.where(mask, pts, pts * numpy.sinh(etas))\n",
    "\n",
    "  isinf = numpy.isinf(pzs)\n",
    "\n",
    "  if numpy.any(isinf):\n",
    "    print(\"inf from eta:\")\n",
    "    print(etas[isinf])\n",
    "    raise ValueError(\"infinity from sinh(eta)\")\n",
    "\n",
    "  return numpy.concatenate([pxs, pys, pzs], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pads inputs with nans up to the given maxsize\n",
    "def pad(xs, maxsize):\n",
    "  #Find 'none' values in array and replace with MASKVAL (= fill_none)\n",
    "  ys = \\\n",
    "    awkward.fill_none \\\n",
    "  ( awkward.pad_none(xs, maxsize, axis=1, clip=True) #Adding 'none' values to make sure it is correct size\n",
    "  , MASKVAL\n",
    "  )[:,:maxsize]\n",
    "\n",
    "  return awkward.to_regular(ys, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten1(xs, maxsize=-1):\n",
    "  ys = {}\n",
    "  for field in xs.fields:\n",
    "    zs = xs[field]\n",
    "    if maxsize > 0:\n",
    "      zs = pad(zs, maxsize)\n",
    "    ys[field] = zs\n",
    "\n",
    "  return awkward.zip(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define histogram plotting functions\n",
    "# returns a fixed set of bin edges\n",
    "def fixedbinning(xmin, xmax, nbins):\n",
    "  return numpy.mgrid[xmin:xmax:nbins*1j]\n",
    "\n",
    "\n",
    "# define two functions to aid in plotting\n",
    "def hist(xs, binning, normalized=False):\n",
    "  ys = numpy.histogram(xs, bins=binning)[0]\n",
    "\n",
    "  yerrs = numpy.sqrt(ys)\n",
    "\n",
    "  if normalized:\n",
    "    s = numpy.sum(ys)\n",
    "    ys = ys / s\n",
    "    yerrs = yerrs / s\n",
    "\n",
    "  return ys, yerrs\n",
    "\n",
    "\n",
    "def binneddensity(xs, binning, label=None, xlabel=None, ylabel=\"binned probability density\"):\n",
    "  fig = figure.Figure(figsize=(8, 8))\n",
    "  plt = fig.add_subplot(111)\n",
    "\n",
    "  ys , yerrs = hist(xs, binning, normalized=True)\n",
    "\n",
    "  # determine the central value of each histogram bin\n",
    "  # as well as the width of each bin\n",
    "  # this assumes a fixed bin size.\n",
    "  xs = (binning[1:]+binning[:-1]) / 2.0\n",
    "  xerrs = ((binning[1:]-binning[:-1]) / 2.0)\n",
    "\n",
    "  plt.errorbar \\\n",
    "    ( xs\n",
    "    , ys\n",
    "    , xerr=xerrs\n",
    "    , yerr=yerrs\n",
    "    , label=label\n",
    "    , linewidth=0\n",
    "    , elinewidth=2\n",
    "    )\n",
    "\n",
    "  plt.set_xlabel(xlabel)\n",
    "  plt.set_ylabel(ylabel)\n",
    "\n",
    "  return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = \\\n",
    "  features[awkward.sum(features[\"AnalysisAntiKt4TruthJets_pt\"] > 25000, axis=1) > 0]\n",
    "\n",
    "jets1 = events[jetfeatures][:,0] #First jet\n",
    "tracks = events[trackfeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchedtracks = tracks[matchTracks(jets1, tracks)] \n",
    "matchedtracks = flatten1(matchedtracks, MAXTRACKS) #Turn into regular np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "bjets = awkward.sum(jets1[\"AnalysisAntiKt4TruthJets_ghostB_pt\"] > 5000, axis=1) > 0 #Find b hadron jets with certain momentum\n",
    "jets2 = jets1[bjets] #Jets identified as b jets are only jets considered\n",
    "bhadspt= jets2[\"AnalysisAntiKt4TruthJets_ghostB_pt\"][:,0] #np Stack here - Each sub array contains all the features of the jet (axis -1)\n",
    "bhadseta = jets2[\"AnalysisAntiKt4TruthJets_ghostB_eta\"][:, 0]\n",
    "bhadsphi = jets2[\"AnalysisAntiKt4TruthJets_ghostB_phi\"][:,0]\n",
    "matchedtracks = matchedtracks[bjets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "jets3 = structured_to_unstructured(jets2[jetfeatures[:-3]]) #number of features\n",
    "matchedtracks = structured_to_unstructured(matchedtracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11493/2834944321.py:32: RuntimeWarning: overflow encountered in sinh\n",
      "  pzs = numpy.where(mask, pts, pts * numpy.sinh(etas))\n"
     ]
    }
   ],
   "source": [
    "jets4 = ptetaphi2pxpypz(jets3).to_numpy()\n",
    "tracks = ptetaphi2pxpypz2(matchedtracks.to_numpy())\n",
    "bhadspt = bhadspt.to_numpy()\n",
    "bhadseta = bhadseta.to_numpy()\n",
    "bhadsphi = bhadsphi.to_numpy()\n",
    "bhads = numpy.stack([bhadspt, bhadseta, bhadsphi], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the training model\n",
    "\n",
    "tracklayers = [ 32 , 32 , 32 , 32 , 32 ]\n",
    "jetlayers = [ 64 , 64 , 64 , 64 , 64 ]\n",
    "\n",
    "def buildModel(tlayers, jlayers, ntargets):\n",
    "  inputs = layers.Input(shape=(None, tlayers[0]))\n",
    "\n",
    "  outputs = inputs\n",
    "  outputs = layers.Masking(mask_value=MASKVAL)(outputs)\n",
    "\n",
    "  for nodes in tlayers[:-1]:\n",
    "    outputs = layers.Dropout(0.3)(outputs)\n",
    "    outputs = layers.TimeDistributed(layers.Dense(nodes, activation='relu'))(outputs)\n",
    "    outputs = layers.BatchNormalization()(outputs)\n",
    "\n",
    "  outputs = layers.TimeDistributed(layers.Dense(tlayers[-1], activation='softmax'))(outputs)\n",
    "  outputs = Sum()(outputs)\n",
    "\n",
    "  for nodes in jlayers:\n",
    "    outputs = layers.Dropout(0.3)(outputs)\n",
    "    outputs = layers.Dense(nodes, activation='relu')(outputs)\n",
    "    outputs = layers.BatchNormalization()(outputs)\n",
    "\n",
    "  outputs = layers.Dense(ntargets + ntargets*(ntargets+1)//2)(outputs)\n",
    "\n",
    "  return \\\n",
    "    keras.Model \\\n",
    "    ( inputs = inputs\n",
    "    , outputs = outputs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generalise loss to n targets\n",
    "##Convert b hadron features to cartesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the loss function\n",
    "# this ignores any dimension beyond the first!\n",
    "def LogNormal1D(true, meanscovs):\n",
    "  ntargets = true.shape[1] #Number of variables predicting\n",
    "  means = meanscovs[:,:ntargets] #First n targets are the means\n",
    "  # ensure diagonal is positive\n",
    "  logsigma = meanscovs[:,ntargets:2*ntargets]\n",
    "  rest = meanscovs[:,2*ntargets:]\n",
    "\n",
    "  # TODO\n",
    "  # build matrix\n",
    "  loss = 0\n",
    "  for x in range(ntargets):\n",
    "    loss = loss + ((means[:,x] - true[:,x])**2 / (2*keras.backend.exp(logsigma[:,x])**2)) + logsigma[:,x]\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = buildModel([len(trackfeatures)] + tracklayers, jetlayers, 3)\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "model.compile \\\n",
    "  ( loss = LogNormal1D\n",
    "  , optimizer = keras.optimizers.Adam(learning_rate=LR)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68143, 8, 3)\n",
      "[1.37346188e+05 8.16028237e-01 1.20712149e+00]\n",
      "[[ 6209.26450298 13355.34468861 12169.39804895]\n",
      " [  332.31549738  3367.86154568  3007.97056318]\n",
      " [13929.08789537 37259.15905185 37689.85826002]\n",
      " [  895.76702185  1391.20435716  1802.68682528]\n",
      " [  126.80887282   734.25512833   518.3439794 ]\n",
      " [  137.88256407  2120.73090004  2343.21656601]\n",
      " [  210.391507    5898.674895    5550.99705111]\n",
      " [ -998.          -998.          -998.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Splits the data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(tracks, bhads, train_size = 0.75)\n",
    "print(numpy.shape(tracks))\n",
    "print(bhads[0])\n",
    "print(tracks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "799/799 [==============================] - 6s 5ms/step - loss: 6749931008.0000 - val_loss: 1457355648.0000 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 858365440.0000 - val_loss: 559065472.0000 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 345677728.0000 - val_loss: 275744096.0000 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 162831360.0000 - val_loss: 106981888.0000 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 82430832.0000 - val_loss: 71723392.0000 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 44246976.0000 - val_loss: 35731164.0000 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 24633548.0000 - val_loss: 22833180.0000 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 14084455.0000 - val_loss: 11755390.0000 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 7869673.5000 - val_loss: 5618887.0000 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 4790175.0000 - val_loss: 4077092.0000 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 2789707.5000 - val_loss: 2441800.2500 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 1712968.2500 - val_loss: 1510374.5000 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 1036470.7500 - val_loss: 767720.1250 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 637315.8750 - val_loss: 535373.7500 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 393282.8750 - val_loss: 367993.8438 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 244184.9844 - val_loss: 196951.0469 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 157916.2812 - val_loss: 132092.7812 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 98154.1797 - val_loss: 89055.0547 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 60496.2773 - val_loss: 56381.8359 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 39924.5430 - val_loss: 27916.6719 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 24046.0020 - val_loss: 17910.0938 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 15609.3633 - val_loss: 15391.1367 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 10057.5732 - val_loss: 8758.0010 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 6406.5874 - val_loss: 5212.6597 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 4123.4546 - val_loss: 3304.2024 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 2706.2710 - val_loss: 2218.2139 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 1755.6626 - val_loss: 1515.1281 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 1101.4470 - val_loss: 935.4176 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 722.3510 - val_loss: 591.4517 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 474.0682 - val_loss: 454.9115 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 308.6224 - val_loss: 276.9172 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 208.6477 - val_loss: 160.6272 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 136.0606 - val_loss: 117.0634 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 94.0410 - val_loss: 81.8834 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 65.5190 - val_loss: 61.5595 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 46.0141 - val_loss: 44.5905 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 34.3030 - val_loss: 29.2661 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 27.2665 - val_loss: 27.2310 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 22.0817 - val_loss: 21.2501 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 18.8218 - val_loss: 17.8976 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 17.0781 - val_loss: 15.7685 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 15.6797 - val_loss: 14.8053 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 14.9265 - val_loss: 14.1050 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 14.4884 - val_loss: 14.1404 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 14.2625 - val_loss: 13.7756 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 14.1520 - val_loss: 13.7732 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 14.1106 - val_loss: 13.7089 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 14.0872 - val_loss: 13.6839 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 14.0866 - val_loss: 13.7054 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 14.0841 - val_loss: 13.7213 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 14.0783 - val_loss: 13.7138 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 14.0638 - val_loss: 13.7175 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 14.0465 - val_loss: 13.7263 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 14.0224 - val_loss: 13.7260 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 13.9908 - val_loss: 13.6945 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 13.9579 - val_loss: 13.6789 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 13.9240 - val_loss: 13.6654 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 13.8809 - val_loss: 13.6754 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 13.8341 - val_loss: 13.6760 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 13.7835 - val_loss: 13.5653 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 13.7169 - val_loss: 13.6592 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 13.6237 - val_loss: 13.5825 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 13.4872 - val_loss: 13.0652 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 13.3145 - val_loss: 12.9756 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 13.0941 - val_loss: 12.5904 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.9332 - val_loss: 13.7364 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.8122 - val_loss: 13.6612 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.7336 - val_loss: 13.4393 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 12.6642 - val_loss: 15.5293 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 12.6118 - val_loss: 12.7311 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.5648 - val_loss: 12.2022 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.5433 - val_loss: 12.4405 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.5219 - val_loss: 13.9225 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.4790 - val_loss: 12.1174 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.4607 - val_loss: 15.0074 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 12.4499 - val_loss: 16.5312 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.4136 - val_loss: 15.3302 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.4216 - val_loss: 14.1470 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 12.3949 - val_loss: 12.0031 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.3905 - val_loss: 16.0270 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.3833 - val_loss: 15.9276 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 12.3659 - val_loss: 15.1005 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 12.3529 - val_loss: 16.8400 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 12.3474 - val_loss: 17.3867 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.3565 - val_loss: 12.1726 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 12.3573 - val_loss: 16.8467 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 12.3314 - val_loss: 13.3440 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.3264 - val_loss: 15.8131 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.3183 - val_loss: 14.8043 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.3033 - val_loss: 12.1576 - lr: 8.0000e-04\n",
      "Epoch 91/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.2869 - val_loss: 12.2496 - lr: 8.0000e-04\n",
      "Epoch 92/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.2987 - val_loss: 14.2378 - lr: 8.0000e-04\n",
      "Epoch 93/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.2884 - val_loss: 14.0746 - lr: 8.0000e-04\n",
      "Epoch 94/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.2856 - val_loss: 13.6728 - lr: 8.0000e-04\n",
      "Epoch 95/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.2803 - val_loss: 12.2709 - lr: 8.0000e-04\n",
      "Epoch 96/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.2727 - val_loss: 13.8211 - lr: 8.0000e-04\n",
      "Epoch 97/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 12.2726 - val_loss: 15.0278 - lr: 8.0000e-04\n",
      "Epoch 98/1000\n",
      "799/799 [==============================] - 4s 4ms/step - loss: 12.2749 - val_loss: 15.6090 - lr: 8.0000e-04\n",
      "Epoch 99/1000\n",
      "799/799 [==============================] - 3s 4ms/step - loss: 12.2665 - val_loss: 15.8686 - lr: 8.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Trains the data\n",
    "history = model.fit(X_train, y_train, validation_data = (X_valid, y_valid), batch_size=BATCHSIZE, callbacks =[early_stopping, reduce_lr], epochs=EPOCHS)\n",
    "\n",
    "#Plots and saves the loss curve\n",
    "history_df = numpy.log(pd.DataFrame(history.history))\n",
    "fig=plt.figure()\n",
    "LossFigure = history_df.loc[:, ['loss', 'val_loss']].plot().get_figure()\n",
    "LossFigure.savefig('Loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model/assets\n"
     ]
    }
   ],
   "source": [
    "#Saves the model\n",
    "model.save('Model')\n",
    "model.save_weights('Model Weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2130/2130 [==============================] - 2s 898us/step\n"
     ]
    }
   ],
   "source": [
    "# Uses the model to predict validation set\n",
    "pred = model.predict(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.377434  11.417575  11.6138315 ... 11.379891  11.362263  11.341862 ]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 1 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11493/4270814132.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpTDiff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbhads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbhads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpTErr\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mPull\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpTDiff\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpTErr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 1 with size 3"
     ]
    }
   ],
   "source": [
    "# Saves the variables we want from the model\n",
    "pTDiff=pred[:,0] - bhads[:,0]\n",
    "print(pred[:,3])\n",
    "print(bhads[:,3])\n",
    "pTErr= numpy.exp(pred[:,4])\n",
    "Pull = pTDiff/pTErr\n",
    "print(\"pT max, min, mean = \" + str(numpy.mean(pTDiff)), str(numpy.mean(pTDiff)),  str(numpy.mean(pTDiff)))\n",
    "print(\"Pull max, min, mean = \" + str(numpy.max(Pull)), str(numpy.min(Pull)), str(numpy.mean(Pull)))\n",
    "\n",
    "etaDiff = pred[:,1] - y_valid[:,1]\n",
    "etaErr = numpy.exp(pred[:, 5])\n",
    "scaledEtaDiff = etaDiff/etaErr\n",
    "print('eta max, min, mean = ' + str(numpy.max(etaDiff)), str(numpy.min(etaDiff)), str(numpy.mean(etaDiff)))\n",
    "print('Scaled eta max, min, mean = ' + str(numpy.max(scaledEtaDiff)), str(numpy.min(scaledEtaDiff)), str(numpy.mean(scaledEtaDiff)))\n",
    "\n",
    "phiDiff = pred[:,2] - y_valid[:,2]\n",
    "phiErr = numpy.exp(pred[:, 6])\n",
    "scaledPhiDiff = phiDiff / phiErr\n",
    "print('Phi max, min, mean = ' + str(numpy.max(phiDiff)), str(numpy.min(phiDiff)), str(numpy.mean(phiDiff)))\n",
    "print('Scaled Phi max, min, mean = ' + str(numpy.max(scaledPhiDiff)), str(numpy.min(scaledPhiDiff)), str(numpy.mean(scaledPhiDiff)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11493/1946720118.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ys = ys / s\n",
      "/tmp/ipykernel_11493/1946720118.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  yerrs = yerrs / s\n",
      "/home/physics/phuspv/anaconda3/envs/Luke/lib/python3.9/site-packages/matplotlib/axes/_base.py:2480: UserWarning: Warning: converting a masked element to nan.\n",
      "  xys = np.asarray(xys)\n"
     ]
    }
   ],
   "source": [
    "# Making the plots\n",
    "#The loss curve\n",
    "\n",
    "\n",
    "# The Histograms\n",
    "fig = \\\n",
    "binneddensity \\\n",
    "( Pull\n",
    ", fixedbinning(-5, 5, 100)\n",
    ", xlabel=\"Pull\"\n",
    ")\n",
    "fig.savefig(\"Pull.png\")\n",
    "\n",
    "fig = \\\n",
    "binneddensity \\\n",
    "( pTDiff\n",
    ", fixedbinning(-200000, 200000, 100)\n",
    ", xlabel=\"pT Difference\"\n",
    ")\n",
    "fig.savefig(\"pT Difference.png\")\n",
    "\n",
    "fig = \\\n",
    "binneddensity \\\n",
    "( etaDiff\n",
    ", fixedbinning(-5, 5, 100)\n",
    ", xlabel=\"Eta Diff\"\n",
    ")\n",
    "fig.savefig(\"Eta Diff.png\")\n",
    "\n",
    "fig = \\\n",
    "binneddensity \\\n",
    "( scaledEtaDiff\n",
    ", fixedbinning(-5, 5, 100)\n",
    ", xlabel=\"Scaled Eta Diff\"\n",
    ")\n",
    "fig.savefig(\"scaled Eta Diff.png\")\n",
    "\n",
    "fig = \\\n",
    "binneddensity \\\n",
    "( phiDiff\n",
    ", fixedbinning(-5, 5, 100)\n",
    ", xlabel=\"Phi Diff\"\n",
    ")\n",
    "fig.savefig(\"Phi Diff.png\")\n",
    "\n",
    "fig = \\\n",
    "binneddensity \\\n",
    "( scaledPhiDiff\n",
    ", fixedbinning(-5, 5, 100)\n",
    ", xlabel=\"Scaled Phi Diff\"\n",
    ")\n",
    "fig.savefig(\"Scaled Phi Diff.png\")\n",
    "\n",
    "#Input plots\n",
    "jetz0sintheta = features[\"AnalysisTracks_z0sinTheta\"]\n",
    "impactParam = features[\"AnalysisTracks_d0\"]\n",
    "impactParamSig = features[\"AnalysisTracks_d0sig\"]\n",
    "impactParamPV = features[\"AnalysisTracks_d0PV\"]\n",
    "impactParamPVSig = features[\"AnalysisTracks_d0sigPV\"]\n",
    "fig = \\\n",
    "  binneddensity \\\n",
    "  ( jetz0sintheta[:,0] # the first jet in each event\n",
    "  , fixedbinning(-1, 1, 500) # 50 bins from 0 to 2\n",
    "  , xlabel=\"Transverse IP * sin(Theta)\"\n",
    "  )\n",
    "fig.savefig(\"TransverseIP.png\")\n",
    "\n",
    "fig = \\\n",
    "  binneddensity \\\n",
    "  ( impactParam[:,0] # the first jet in each event\n",
    "  , fixedbinning(-1, 1, 500) # 50 bins from 0 to 2\n",
    "  , xlabel=\"Impact Parameter\"\n",
    "  )\n",
    "fig.savefig(\"Impact Parameter.png\")\n",
    "\n",
    "fig = \\\n",
    "  binneddensity \\\n",
    "  ( impactParamSig[:,0] # the first jet in each event\n",
    "  , fixedbinning(-4, 4, 100) # 50 bins from 0 to 2\n",
    "  , xlabel=\"Impact Parameter Sig\"\n",
    "  )\n",
    "fig.savefig(\"Impact Parameter Sig.png\")\n",
    "\n",
    "fig = \\\n",
    "  binneddensity \\\n",
    "  ( impactParamPV[:,0] # the first jet in each event\n",
    "  , fixedbinning(-0.5, 0.5, 250) # 50 bins from 0 to 2\n",
    "  , xlabel=\"Impact Parameter (PV)\"\n",
    "  )\n",
    "fig.savefig(\"Impact Parameter PV.png\")\n",
    "\n",
    "fig = \\\n",
    "  binneddensity \\\n",
    "  ( impactParamPVSig[:,0] # the first jet in each event\n",
    "  , fixedbinning(-4, 4, 100) # 100 bins from -3 to 3\n",
    "  , xlabel=\"Impact Parameter Sig (PV)\"\n",
    "  )\n",
    "fig.savefig(\"Impact Parameter PV Sig.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pT Diff Mean = -80975.03940487871\n",
      "pT Diff Median = -72908.6767578125\n",
      "pT Diff Std = 42235.858985542865\n",
      "pT Diff IQR = 46577.239013671875\n",
      "Pull Mean = -171284.11768627164\n",
      "Pull Median = -153727.86573908408\n",
      "Pull Std = 98004.6848824112\n",
      "Pull IQR = 107243.49946987844\n"
     ]
    }
   ],
   "source": [
    "#Print any results we want\n",
    "print('pT Diff Mean = ' + str(numpy.mean(pTDiff)))\n",
    "print('pT Diff Median = ' + str(numpy.median(pTDiff)))\n",
    "print('pT Diff Std = ' + str(numpy.std(pTDiff)))\n",
    "print('pT Diff IQR = ' + str(numpy.percentile(pTDiff, 75)-numpy.percentile(pTDiff, 25)))\n",
    "print('Pull Mean = ' + str(numpy.mean(Pull)))\n",
    "print('Pull Median = ' + str(numpy.median(Pull)))\n",
    "print('Pull Std = ' + str(numpy.std(Pull)))\n",
    "print('Pull IQR = ' + str(numpy.percentile(Pull, 75)-numpy.percentile(Pull, 25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PDG ID: 531\n",
      "number of b-hadrons: 13487\n",
      "\n",
      "PDG ID: -521\n",
      "number of b-hadrons: 61531\n",
      "\n",
      "PDG ID: -511\n",
      "number of b-hadrons: 61243\n",
      "\n",
      "PDG ID: 5232\n",
      "number of b-hadrons: 751\n",
      "\n",
      "PDG ID: 511\n",
      "number of b-hadrons: 61706\n",
      "\n",
      "PDG ID: 521\n",
      "number of b-hadrons: 61594\n",
      "\n",
      "PDG ID: -531\n",
      "number of b-hadrons: 13526\n",
      "\n",
      "PDG ID: -5122\n",
      "number of b-hadrons: 5447\n",
      "\n",
      "PDG ID: 5122\n",
      "number of b-hadrons: 5232\n",
      "\n",
      "PDG ID: -5132\n",
      "number of b-hadrons: 676\n",
      "\n",
      "PDG ID: 5132\n",
      "number of b-hadrons: 722\n",
      "\n",
      "PDG ID: -5232\n",
      "number of b-hadrons: 733\n",
      "\n",
      "PDG ID: 555\n",
      "number of b-hadrons: 3\n",
      "\n",
      "PDG ID: 553\n",
      "number of b-hadrons: 6\n",
      "\n",
      "PDG ID: -5332\n",
      "number of b-hadrons: 21\n",
      "\n",
      "PDG ID: 5332\n",
      "number of b-hadrons: 18\n",
      "\n",
      "PDG ID: 100553\n",
      "number of b-hadrons: 1\n",
      "\n",
      "PDG ID: -541\n",
      "number of b-hadrons: 5\n",
      "\n",
      "PDG ID: 10551\n",
      "number of b-hadrons: 3\n",
      "\n",
      "PDG ID: 541\n",
      "number of b-hadrons: 5\n",
      "\n",
      "PDG ID: 20553\n",
      "number of b-hadrons: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "quit()\n",
    "# this creates histograms of truth jet values.\n",
    "truthjetspt = features[\"AnalysisAntiKt4TruthJets_pt\"] \n",
    "truthjetseta = features[\"AnalysisAntiKt4TruthJets_eta\"]\n",
    "truthjetsphi = features[\"AnalysisAntiKt4TruthJets_phi\"]\n",
    "\n",
    "\n",
    "fig = \\\n",
    "  binneddensity \\\n",
    "  ( truthjetspt[:,0] # the first jet in each event\n",
    "  , fixedbinning(0, 200000, 50) # 50 bins from 0 to 200000 MeV\n",
    "  , xlabel=\"First truth jet $p_T$ [MeV]\"\n",
    "  )\n",
    "\n",
    "fig.savefig(\"truthjet-pt-comb.png\")\n",
    "\n",
    "fig = \\\n",
    "  binneddensity \\\n",
    "  ( truthjetseta[:,0] # the first jet in each event\n",
    "  , fixedbinning(-5, 5, 50) # 50 bins from 0 to 5\n",
    "  , xlabel=\"First truth jet pseudorepidity\"\n",
    "  )\n",
    "fig.savefig(\"truthjet-eta-comb.png\")\n",
    "\n",
    "fig = \\\n",
    "  binneddensity \\\n",
    "  ( truthjetsphi[:,0] # the first jet in each event\n",
    "  , fixedbinning(0, 3.15, 50) # 50 bins from 0 to pi rad\n",
    "  , xlabel=\"First truth jet phi [rad]\"\n",
    "  )\n",
    "fig.savefig(\"truthjet-phi-comb.png\")\n",
    "\n",
    "\n",
    "# this creates histograms of the reconstructed jet values.\n",
    "reconstructedjetspt = features[\"AnalysisJets_pt_NOSYS\"]\n",
    "reconstructedjetseta = features[\"AnalysisJets_eta\"]\n",
    "reconstructedjetsphi = features[\"AnalysisJets_phi\"]\n",
    "\n",
    "\n",
    "pt_filt = []\n",
    "eta_filt = []\n",
    "phi_filt = []\n",
    "\n",
    "for x in range(len(reconstructedjetspt)):\n",
    "    if numpy.sum(numpy.absolute(reconstructedjetspt[x])) != 0:\n",
    "        pt_filt.append(reconstructedjetspt[x][0])\n",
    "    if numpy.sum(numpy.absolute(reconstructedjetseta[x])) != 0:\n",
    "        eta_filt.append(reconstructedjetseta[x][0])\n",
    "    if numpy.sum(numpy.absolute(reconstructedjetsphi[x])) != 0:\n",
    "        phi_filt.append(reconstructedjetsphi[x][0])\n",
    "\n",
    "fig = \\\n",
    "  binneddensity \\\n",
    "  ( pt_filt # the first jet in each event\n",
    "  , fixedbinning(0, 200000, 50) # 50 bins from 0 to 200000 MeV\n",
    "  , xlabel=\"Reconstructed jet $p_T$ [MeV]\"\n",
    "  )\n",
    "fig.savefig(\"Reconstructedjet-pT-comb.png\")\n",
    "\n",
    "fig = \\\n",
    "  binneddensity \\\n",
    "  ( eta_filt # the first jet in each event\n",
    "  , fixedbinning(-5, 5, 50) # 50 bins from -5 to 5\n",
    "  , xlabel=\"Reconstructed jet pseudorapidity\"\n",
    "  )\n",
    "fig.savefig(\"reconstructedjet-eta-comb.png\")\n",
    "\n",
    "fig = \\\n",
    "  binneddensity \\\n",
    "  ( phi_filt # the first jet in each event\n",
    "  , fixedbinning(0, 3.15, 50) # 50 bins from 0 to pi rad\n",
    "  , xlabel=\"Reconstructed jet phi [rad]\"\n",
    "  )\n",
    "fig.savefig(\"reconstructedjet-phi-comb.png\")\n",
    "\n",
    "\n",
    "#this creates a histogram of b-hadron pTs\n",
    "b_hadron_pt = features[\"AnalysisAntiKt4TruthJets_ghostB_pt\"] \n",
    "b_hadron_pt = awkward.flatten(b_hadron_pt, axis = None)\n",
    "\n",
    "fig = \\\n",
    "  binneddensity \\\n",
    "  ( b_hadron_pt #the hadron pTs\n",
    "  , fixedbinning(0, 200000, 50) # 50 bins from 0 to 200000 MeV\n",
    "  , xlabel = \"B-Hadron $p_T$ [MeV]\"\n",
    "  )\n",
    "fig.savefig(\"ptDist.png\")\n",
    "\n",
    "# this counts the number of b-hadron identification numbers and prints out the\n",
    "# counts.\n",
    "# these are defined in the PDG (but no need to worry about the details for now!)\n",
    "# https://pdg.lbl.gov/2007/reviews/montecarlorpp.pdf\n",
    "\n",
    "\n",
    "truthbhadronsid = \\\n",
    "  awkward.flatten \\\n",
    "  ( features[\"AnalysisAntiKt4TruthJets_ghostB_pdgId\"]\n",
    "  , axis=None\n",
    "  )\n",
    "\n",
    "# loop over all the b-hadrons associated to jets\n",
    "counts = {}\n",
    "for bhadid in truthbhadronsid:\n",
    "  if bhadid in counts:\n",
    "    counts[bhadid] += 1\n",
    "  else:\n",
    "    counts[bhadid] = 1\n",
    "\n",
    "print()\n",
    "for bhadid in counts:\n",
    "  print(\"PDG ID:\", bhadid)\n",
    "  print(\"number of b-hadrons:\", counts[bhadid])\n",
    "  print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Luke')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6679b2c4fdeb25d2a0cd890f27b2b235b752c32ed605315ad831eb2b3957fc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
